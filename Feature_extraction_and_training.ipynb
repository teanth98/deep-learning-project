{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NefcQj8OmBoa"
      },
      "source": [
        "# **Importing Necessary Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGCoegRXev76",
        "outputId": "5af5286c-3767-4ca5-8364-b56d425d67f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-gdcm in /usr/local/lib/python3.7/dist-packages (3.0.12)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "tensorflow: 2.8.0\n",
            "keras: 2.8.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package to_categorical\n"
          ]
        }
      ],
      "source": [
        "# tensorflow version\n",
        "!pip install -U python-gdcm\n",
        "!pip install Pillow\n",
        "import tensorflow\n",
        "import PIL\n",
        "from PIL import UnidentifiedImageError\n",
        "print('tensorflow: %s' % tensorflow.__version__)\n",
        "# keras version\n",
        "import keras\n",
        "print('keras: %s' % keras.__version__)\n",
        "from os import listdir\n",
        "from pickle import dump\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n",
        "from numpy import argmax\n",
        "from pickle import load\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "import string\n",
        "# !pip install keras.utils\n",
        "!apt install to_categorical\n",
        "from numpy import array\n",
        "from pickle import load\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from keras.layers.merge import add\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from os import listdir\n",
        "from pickle import dump\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nde7Z6pszO6E",
        "outputId": "020e21be-0863-45ba-ee28-34590616df16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlRLs0UmmGXj"
      },
      "source": [
        "# **Extracting Image Features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "APq6gQgRaWVo"
      },
      "outputs": [],
      "source": [
        "def extract_features(directory):\n",
        "  model = VGG16()\n",
        "  model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "  features = dict()\n",
        "  for name in listdir(directory):\n",
        "    try:\n",
        "      # print(x)\n",
        "      filename = directory + '/' + name\n",
        "      image = load_img(filename, target_size=(224,224))\n",
        "      image = img_to_array(image)\n",
        "      image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "      image = preprocess_input(image)\n",
        "      feature = model.predict(image, verbose= 0)\n",
        "      image_id = name.split('.')[0]\n",
        "      features[image_id] = feature\n",
        "      print('>%s' %name)\n",
        "    except UnidentifiedImageError:\n",
        "      continue\n",
        "  return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSVW2M0-4I0e",
        "outputId": "27fc4868-bb64-40ba-b609-6744cea74bcd"
      },
      "outputs": [],
      "source": [
        "# extract features from each photo in the directory\n",
        "# def extract_features(directory):\n",
        "# \tmodel = VGG16()\n",
        "# \tmodel = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "# \tfeatures = dict()\n",
        "# \tfor name in listdir(directory):\n",
        "# \t\ttry:\n",
        "# \t\t\tfilename = directory + '/' + name\n",
        "# \t\t\timage = load_img(filename, target_size=(224, 224))\n",
        "# \t\t\timage = img_to_array(image)\n",
        "# \t\t\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "# \t\t\timage = preprocess_input(image)\n",
        "# \t\t\tfeature = model.predict(image, verbose=0)\n",
        "# \t\t\timage_id = name.split('.')[0]\n",
        "# \t\t\tfeatures[image_id] = feature\n",
        "# \t\t\tprint('>%s' % name)\n",
        "# \t  except PIL.UnidentifiedImageError:\n",
        "# \t\t\tcontinue\n",
        "# \treturn features\n",
        "\n",
        "# extract features from all images\n",
        "directory = '/content/drive/MyDrive/UB assignments/DIC/Flicker8k_Dataset'\n",
        "features = extract_features(directory)\n",
        "print('Extracted Features: %d' % len(features))\n",
        "# save to file\n",
        "# dump(features, open('features.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r60h2Ei5mOFu"
      },
      "source": [
        "# **Saving the features file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "b-5pTm43PQrR"
      },
      "outputs": [],
      "source": [
        "dump(features, open('/content/drive/MyDrive/UB assignments/DIC/features.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GinYdfbQnWWV"
      },
      "source": [
        "# **Preprocessing the text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "piCAdynn1wTO"
      },
      "outputs": [],
      "source": [
        "def load_doc(filename):\n",
        "\tfile = open(filename, 'r')\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text\n",
        " \n",
        "def load_set(filename):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdataset = list()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\tif len(line) < 1:\n",
        "\t\t\tcontinue\n",
        "\t\tidentifier = line.split('.')[0]\n",
        "\t\tdataset.append(identifier)\n",
        "\treturn set(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qgtKkfSLSFDy"
      },
      "outputs": [],
      "source": [
        "def load_clean_descriptions(filename, dataset):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdescriptions = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\ttokens = line.split()\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\tif image_id in dataset:\n",
        "\t\t\tif image_id not in descriptions:\n",
        "\t\t\t\tdescriptions[image_id] = list()\n",
        "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "\t\t\tdescriptions[image_id].append(desc)\n",
        "\treturn descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W34b_kG5c-CT",
        "outputId": "60272de1-3bc4-4838-cfa2-1d150055f6a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded: 8092 \n",
            "Vocabulary Size: 8763\n"
          ]
        }
      ],
      "source": [
        "def load_doc(filename):\n",
        "\tfile = open(filename, 'r')\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "def load_descriptions(doc):\n",
        "\tmapping = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\ttokens = line.split()\n",
        "\t\tif len(line) < 2:\n",
        "\t\t\tcontinue\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\timage_id = image_id.split('.')[0]\n",
        "\t\timage_desc = ' '.join(image_desc)\n",
        "\t\tif image_id not in mapping:\n",
        "\t\t\tmapping[image_id] = list()\n",
        "\t\tmapping[image_id].append(image_desc)\n",
        "\treturn mapping\n",
        " \n",
        "def clean_descriptions(descriptions):\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor i in range(len(desc_list)):\n",
        "\t\t\tdesc = desc_list[i]\n",
        "\t\t\tdesc = desc.split()\n",
        "\t\t\tdesc = [word.lower() for word in desc]\n",
        "\t\t\tdesc = [w.translate(table) for w in desc]\n",
        "\t\t\tdesc = [word for word in desc if len(word)>1]\n",
        "\t\t\tdesc = [word for word in desc if word.isalpha()]\n",
        "\t\t\tdesc_list[i] =  ' '.join(desc)\n",
        " \n",
        "def to_vocabulary(descriptions):\n",
        "\tall_desc = set()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.update(d.split()) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        " \n",
        "def save_descriptions(descriptions, filename):\n",
        "\tlines = list()\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor desc in desc_list:\n",
        "\t\t\tlines.append(key + ' ' + desc)\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()\n",
        " \n",
        "filename = '/content/drive/MyDrive/UB assignments/DIC/Flickr8k_text/Flickr8k.token.txt'\n",
        "doc = load_doc(filename)\n",
        "descriptions = load_descriptions(doc)\n",
        "print('Loaded: %d ' % len(descriptions))\n",
        "clean_descriptions(descriptions)\n",
        "vocabulary = to_vocabulary(descriptions)\n",
        "print('Vocabulary Size: %d' % len(vocabulary))\n",
        "save_descriptions(descriptions, '/content/drive/MyDrive/UB assignments/DIC/descriptions.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "n_S6k2TCSPQd"
      },
      "outputs": [],
      "source": [
        "def load_photo_features(filename, dataset):\n",
        "\tall_features = load(open(filename, 'rb'))\n",
        "\tfeatures = {k: all_features[k] for k in dataset}\n",
        "\treturn features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK6vsWm5SWCF",
        "outputId": "e1f7044e-3dd1-42ba-d89c-6302dd86fc14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 6000\n",
            "Descriptions: train=6000\n",
            "Photos: train=6000\n"
          ]
        }
      ],
      "source": [
        "filename = '/content/drive/MyDrive/UB assignments/DIC/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "print('Dataset: %d' % len(train))\n",
        "train_descriptions = load_clean_descriptions('/content/drive/MyDrive/UB assignments/DIC/descriptions.txt', train)\n",
        "print('Descriptions: train=%d' % len(train_descriptions))\n",
        "train_features = load_photo_features('/content/drive/MyDrive/UB assignments/DIC/features.pkl', train)\n",
        "print('Photos: train=%d' % len(train_features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25wdrvhQsGLm"
      },
      "source": [
        "# **Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxthKhonS3gV",
        "outputId": "b58cbd93-494c-46d9-f5a8-206ef96d1089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 7579\n"
          ]
        }
      ],
      "source": [
        "def to_lines(descriptions):\n",
        "\tall_desc = list()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.append(d) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        " \n",
        "def create_tokenizer(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        " \n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KosyHSIIS5AV"
      },
      "outputs": [],
      "source": [
        "def create_sequences(tokenizer, max_length, descriptions, photos, vocab_size):\n",
        "\tX1, X2, y = list(), list(), list()\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor desc in desc_list:\n",
        "\t\t\tseq = tokenizer.texts_to_sequences([desc])[0]\n",
        "\t\t\tfor i in range(1, len(seq)):\n",
        "\t\t\t\tin_seq, out_seq = seq[:i], seq[i]\n",
        "\t\t\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "\t\t\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "\t\t\t\tX1.append(photos[key][0])\n",
        "\t\t\t\tX2.append(in_seq)\n",
        "\t\t\t\ty.append(out_seq)\n",
        "\treturn array(X1), array(X2), array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YrgXBKDPTBrF"
      },
      "outputs": [],
      "source": [
        "def max_length(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\treturn max(len(d.split()) for d in lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0vWvFVPriD_"
      },
      "source": [
        "# **Creating the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "CJuCA4ZkTGvI"
      },
      "outputs": [],
      "source": [
        "def define_model(vocab_size, max_length):\n",
        "\tinputs1 = Input(shape=(4096,))\n",
        "\tfe1 = Dropout(0.5)(inputs1)\n",
        "\tfe2 = Dense(256, activation='relu')(fe1)\n",
        "\tinputs2 = Input(shape=(max_length,))\n",
        "\tse1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
        "\tse2 = Dropout(0.5)(se1)\n",
        "\tse3 = LSTM(256)(se2)\n",
        "\tdecoder1 = add([fe2, se3])\n",
        "\tdecoder2 = Dense(256, activation='relu')(decoder1)\n",
        "\toutputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "\tmodel = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\tprint(model.summary())\n",
        "\tplot_model(model, to_file='model.png', show_shapes=True)\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5Edr5D9U0HS",
        "outputId": "6f4ffdea-5021-4b01-c1ec-55e8d86369f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 34)]         0           []                               \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 4096)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 34, 256)      1940224     ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 4096)         0           ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 34, 256)      0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          1048832     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 256)          525312      ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 256)          0           ['dense[0][0]',                  \n",
            "                                                                  'lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 256)          65792       ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 7579)         1947803     ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,527,963\n",
            "Trainable params: 5,527,963\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "filename = '/content/drive/MyDrive/UB assignments/DIC/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "train_descriptions = load_clean_descriptions('/content/drive/MyDrive/UB assignments/DIC/descriptions.txt', train)\n",
        "train_features = load_photo_features('/content/drive/MyDrive/UB assignments/DIC/features.pkl', train)\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_length = max_length(train_descriptions)\n",
        "X1train, X2train, ytrain = create_sequences(tokenizer, max_length, train_descriptions, train_features, vocab_size)\n",
        "filename = '/content/drive/MyDrive/UB assignments/DIC/Flickr8k_text/Flickr_8k.devImages.txt'\n",
        "test = load_set(filename)\n",
        "test_descriptions = load_clean_descriptions('/content/drive/MyDrive/UB assignments/DIC/descriptions.txt', test)\n",
        "test_features = load_photo_features('/content/drive/MyDrive/UB assignments/DIC/features.pkl', test)\n",
        "X1test, X2test, ytest = create_sequences(tokenizer, max_length, test_descriptions, test_features, vocab_size)\n",
        "model = define_model(vocab_size, max_length)\n",
        "filepath = '/content/drive/MyDrive/UB assignments/DIC/model-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbG6qBMoZ5Rn"
      },
      "outputs": [],
      "source": [
        "model.fit([X1train, X2train], ytrain, epochs=20, verbose=2, callbacks=[checkpoint], validation_data=([X1test, X2test], ytest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCEYUvwdjpa3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Feature_extraction_and_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
